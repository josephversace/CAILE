# **How the IIM Platform Works**

Based on my analysis of your codebase, here's a comprehensive explanation of how the Intelligent Investigation Machine (IIM) operates:## **How the IIM Platform Works**

The Intelligent Investigation Machine (IIM) is a sophisticated **local-first AI investigation platform** designed for law enforcement and security professionals. It's a complete desktop application that runs entirely on-premises, ensuring data privacy and operational security.

## **System Architecture Overview**

```
┌─────────────────────────────────────────────────────────────┐
│                    Framework Desktop PC                      │
│  (128GB RAM, AMD Ryzen, ROCm GPU, 2TB NVMe)               │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  ┌──────────────────────────────────────────────────────┐  │
│  │           Windows 11 + .NET 8 Runtime                 │  │
│  ├──────────────────────────────────────────────────────┤  │
│  │                                                       │  │
│  │  ┌─────────────────┐      ┌────────────────────┐    │  │
│  │  │  IIM Desktop UI  │◄────►│   IIM API Daemon   │    │  │
│  │  │  (Blazor Hybrid) │      │  (Minimal APIs)    │    │  │
│  │  └─────────────────┘      └──────┬─────────────┘    │  │
│  │                                   │                   │  │
│  └───────────────────────────────────┼───────────────────┘  │
│                                      │                       │
│  ┌───────────────────────────────────▼───────────────────┐  │
│  │                    WSL2 Ubuntu                         │  │
│  ├────────────────────────────────────────────────────────┤  │
│  │  ┌──────────┐  ┌──────────┐  ┌──────────────────┐   │  │
│  │  │  Qdrant  │  │ Embedding│  │   AI Models      │   │  │
│  │  │  Vector  │  │  Service │  │  (Ollama/ONNX)   │   │  │
│  │  │   Store  │  │ (FastAPI)│  │                  │   │  │
│  │  └──────────┘  └──────────┘  └──────────────────┘   │  │
│  └────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────┘
```

## **Core Components & Their Roles**

### **1. IIM Desktop Application (UI Layer)**
- **Technology**: Blazor Hybrid using WebView2
- **Purpose**: Primary user interface for investigators
- **Key Features**:
  - Drag-and-drop evidence ingestion
  - Investigation session management
  - Real-time AI model interaction
  - Visual analysis tools and dashboards

### **2. IIM API Daemon (Business Logic)**
- **Technology**: .NET 8 Minimal APIs
- **Purpose**: Central orchestration hub
- **Responsibilities**:
  - Model lifecycle management
  - Evidence processing pipeline
  - Session state management
  - Tool execution coordination

### **3. WSL2 Infrastructure (AI Services)**
- **Qdrant Vector Database**: Stores document embeddings for semantic search
- **Embedding Service**: Converts text/images to vectors using SentenceTransformers
- **Model Runtime**: Hosts AI models via Ollama, ONNX Runtime, or custom providers

## **Investigation Workflow - Step by Step**

### **Phase 1: Evidence Ingestion**

```csharp
// User drags files into the UI
1. Files dropped → IIM Desktop UI
2. UI sends to → API Daemon
3. Daemon processes:
   - Calculates SHA-256 hash (integrity)
   - Extracts text (PDFs, DOCX, images via OCR)
   - Generates embeddings via FastAPI service
   - Stores vectors in Qdrant
   - Logs to evidence manifest
```

**What happens technically:**
- **PDF/DOCX**: Parsed using PdfPig/OpenXML libraries
- **Images**: OCR via Tesseract, visual embeddings via CLIP
- **Audio**: Transcribed using Whisper model
- **Video**: Frame extraction + image analysis

### **Phase 2: Investigation Session**

When an investigator starts a new investigation:

```csharp
// Creating an investigation session
var session = await InvestigationService.CreateSessionAsync(new CreateSessionRequest
{
    CaseId = "OP-SHADOW-2024",
    Title = "Financial fraud investigation",
    Models = new Dictionary<string, ModelConfiguration>
    {
        ["text"] = new() { ModelId = "llama3.1:70b" },
        ["vision"] = new() { ModelId = "llava:34b" },
        ["audio"] = new() { ModelId = "whisper-large-v3" }
    },
    EnabledTools = ["rag_search", "timeline_builder", "entity_extractor"]
});
```

### **Phase 3: Query Processing (RAG Pipeline)**

When an investigator asks a question:

```
User Query: "Find all financial transactions related to John Doe in the last 72 hours"
                    ↓
1. Query Embedding: Convert to vector using embedding model
                    ↓
2. Vector Search: Find top-K similar chunks in Qdrant
                    ↓
3. Context Retrieval: Fetch original documents/evidence
                    ↓
4. Prompt Construction: Build grounded prompt with context
                    ↓
5. LLM Generation: Generate answer using loaded model
                    ↓
6. Citation Linking: Map response back to evidence sources
                    ↓
7. Response Display: Show answer with clickable citations
```

**Technical Implementation:**
```csharp
public async Task<InvestigationResponse> ProcessQueryAsync(string query)
{
    // Step 1: Embed the query
    var queryVector = await _embeddingService.EmbedTextAsync(query);
    
    // Step 2: Search Qdrant for relevant chunks
    var searchResults = await _qdrantClient.SearchAsync(
        collection: "case_evidence",
        vector: queryVector,
        limit: 5,
        score_threshold: 0.7f
    );
    
    // Step 3: Build context from search results
    var context = BuildContextFromResults(searchResults);
    
    // Step 4: Generate response using LLM
    var prompt = $@"
        Context: {context}
        Question: {query}
        Instructions: Answer based only on the provided context.
        Include specific references to evidence.";
    
    var response = await _inferenceService.InferAsync(
        modelId: "llama3.1:70b",
        prompt: prompt
    );
    
    // Step 5: Extract and link citations
    var citations = ExtractCitations(response, searchResults);
    
    return new InvestigationResponse
    {
        Message = response,
        Citations = citations,
        EvidenceIds = searchResults.Select(r => r.EvidenceId).ToList()
    };
}
```

### **Phase 4: Multi-Modal Analysis**

The platform can combine different AI models for comprehensive analysis:

```csharp
// Example: Analyzing surveillance footage with audio
1. Video Input → Frame extraction (every N seconds)
2. Each frame → CLIP model for visual analysis
3. Audio track → Whisper for transcription
4. Combined analysis → LLM for narrative generation
5. Timeline construction → Temporal correlation of events
```

### **Phase 5: Evidence Chain & Export**

Every action is logged for chain of custody:

```csharp
public class EvidenceEntry
{
    public string Id { get; set; }           // Unique identifier
    public string Hash { get; set; }         // SHA-256 hash
    public DateTime IngestedAt { get; set; } // Timestamp
    public string IngestedBy { get; set; }   // User ID
    public List<AuditLog> AccessLog { get; set; } // Who accessed when
}
```

## **Key Features in Action**

### **1. Retrieval-Augmented Generation (RAG)**
- **Purpose**: Ground AI responses in actual evidence
- **How it works**: Semantic search finds relevant documents, LLM generates answers from those specific sources
- **Benefit**: Reduces hallucination, provides traceable answers

### **2. Multi-Model Orchestration**
```csharp
// The platform can run multiple models simultaneously
var tasks = new[]
{
    TranscribeAudioAsync("interview.mp3"),        // Whisper
    AnalyzeImagesAsync(suspectPhotos),            // CLIP
    ExtractEntitiesAsync(caseDocuments),          // NER model
    BuildTimelineAsync(allEvidence)               // Custom model
};

var results = await Task.WhenAll(tasks);
var combinedAnalysis = await SynthesizeResults(results);
```

### **3. Local-First Security**
- **All processing happens on-device** (no cloud dependencies)
- **Air-gapped operation** supported for sensitive cases
- **Evidence integrity** via cryptographic hashing
- **Audit logging** for every operation

### **4. Tool Execution Pipeline**

Investigators can use specialized tools:

```csharp
// Timeline Builder Tool
var timeline = await ExecuteToolAsync("timeline_builder", new
{
    EvidenceIds = ["doc1", "doc2", "phone_records"],
    TimeRange = "2024-01-15 to 2024-01-18",
    Resolution = "hourly"
});

// Entity Relationship Mapper
var entityGraph = await ExecuteToolAsync("entity_mapper", new
{
    Documents = caseDocuments,
    EntityTypes = ["person", "organization", "location", "phone", "email"]
});
```

## **Real Investigation Example**

Here's how an actual investigation flows through the system:

```
1. EVIDENCE UPLOAD
   Investigator uploads:
   - 50 PDFs (financial records)
   - 200 images (surveillance)
   - 10 MP3s (phone intercepts)
   - 1 Excel (call records)

2. AUTOMATIC PROCESSING
   System automatically:
   - Extracts text from all PDFs
   - Transcribes all audio files
   - Performs OCR on images
   - Identifies faces and objects
   - Creates searchable index

3. INVESTIGATION QUERIES
   Investigator asks:
   "Who did John Doe call between Jan 15-17?"
   
   System:
   - Searches call records
   - Correlates with transcripts
   - Identifies mentioned names
   - Returns: "John Doe made 15 calls to 3 unique numbers..."

4. CROSS-REFERENCE
   "Show me images of anyone John called"
   
   System:
   - Takes names from call analysis
   - Searches surveillance images
   - Uses face recognition
   - Returns matching photos with timestamps

5. REPORT GENERATION
   System compiles:
   - Timeline of events
   - Network diagram of connections
   - Evidence summary with citations
   - Exportable case package
```

## **Performance Characteristics**

With your 128GB RAM Framework Desktop:
- **Model Capacity**: Can run 70B parameter models locally
- **Concurrent Models**: 3-5 models simultaneously
- **Processing Speed**: 
  - Text: ~50 tokens/second (LLM)
  - Images: ~2 seconds per image (CLIP)
  - Audio: Real-time transcription (Whisper)
- **Storage**: ~10,000 documents indexed per GB

## **Why This Architecture?**

1. **Privacy**: All data stays on-premises
2. **Security**: Air-gapped operation possible
3. **Performance**: Local inference = low latency
4. **Flexibility**: Swap models based on investigation needs
5. **Auditability**: Complete chain of custody
6. **Scalability**: Can process massive evidence sets

The IIM platform essentially turns a high-powered desktop into a complete AI investigation lab, giving investigators powerful tools while maintaining the security and privacy requirements of law enforcement work.